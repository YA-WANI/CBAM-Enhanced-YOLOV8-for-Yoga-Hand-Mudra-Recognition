# -*- coding: utf-8 -*-
"""Visualization of Detections and Heatmaps

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fi0TBK3f5SCU-HJU8mCCTY11kB1_KDe2
"""

import cv2
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from ultralytics import YOLO

# Load trained CBAM-enhanced YOLOv8 model
model_cbam = YOLO('/kaggle/working/runs/detect/train3/weights/best.pt')  # Update path

# Directory Setup
unseen_images_dir = Path('/kaggle/input/real-world-data/Frames_Real_World/Adi Mudra/Adi-02(Front view)')
output_dir = Path('/kaggle/input/real-world-data/Frames_Real_World')
output_dir.mkdir(parents=True, exist_ok=True)

class_names = model_cbam.names
print(f"Classes: {class_names}")

# Identify the CBAM layer (based on your custom model structure)
# E.g., backbone model[8] is where CBAM was inserted in your code
target_layer = model_cbam.model.model[8]  # Adjust this index if needed

# Hook to capture CBAM output
activation_maps = {}

def get_activation(name):
    def hook(model, input, output):
        activation_maps[name] = output.detach()
    return hook

hook_handle = target_layer.register_forward_hook(get_activation("cbam_out"))

# Run Inference & Visualize Attention
for img_path in sorted(unseen_images_dir.glob("*.png")) + sorted(unseen_images_dir.glob("*.jpg")):
    print(f"\nProcessing: {img_path.name}")
    activation_maps.clear()

    # Run prediction
    result = model_cbam(img_path, verbose=False, conf=0.05)[0]

    # Load and resize image
    img = cv2.imread(str(img_path))
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, (640, 640))

    final_label = "No Detection"
    max_conf = -1.0

    if result.boxes and result.boxes.xyxy.numel() > 0:
        boxes = result.boxes.xyxy.cpu().numpy()
        classes = result.boxes.cls.cpu().numpy().astype(int)
        confs = result.boxes.conf.cpu().numpy()

        print(f" {len(boxes)} boxes detected")

        for box, cls_id, conf in zip(boxes, classes, confs):
            x1, y1, x2, y2 = map(int, box)
            label = f"{class_names[cls_id]} {conf:.2f}"
            if conf > max_conf:
                max_conf = conf
                final_label = f"{class_names[cls_id]} ({conf:.2f})"
            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img_rgb, label, (x1, min(img_rgb.shape[0] - 10, y2 + 20)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
    else:
        print("No boxes predicted.")

    cv2.putText(img_rgb, f"Final Prediction: {final_label}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

    #  Extract CBAM Attention Map
    fmap = activation_maps["cbam_out"][0]  # First image in batch
    fmap_mean = fmap.mean(dim=0).cpu().numpy()  # Mean across channels
    fmap_norm = cv2.normalize(fmap_mean, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    fmap_resized = cv2.resize(fmap_norm, (img_rgb.shape[1], img_rgb.shape[0]))

    # Create and overlay heatmap
    heatmap = cv2.applyColorMap(fmap_resized, cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(img_rgb, 0.6, heatmap, 0.4, 0)

    save_path = output_dir / f"{img_path.stem}_cbam_attention.jpg"
    cv2.imwrite(str(save_path), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))

    # Display
    plt.figure(figsize=(10, 8))
    plt.imshow(overlay)
    plt.title(f"{img_path.name} | CBAM Attention Map + Prediction")
    plt.axis("off")
    plt.show()

# Remove Hook
hook_handle.remove()